{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUYNznMdxwMU"
      },
      "source": [
        "<center><span style=\"color:blue; font-family:Georgia;  font-size:2em;\">\n",
        "    <h1>PageRank</h1></span></center>\n",
        "    <p> </p>\n",
        "    <p> </p>\n",
        "    <center><span style=\"color:blue; font-family:Georgia;  font-size:1em;\">\n",
        "    Ramon Béjar</span></center>\n",
        "    <canvas id=\"myCanvas\" width=\"200\" height=\"100\" style=\"border:0px solid\"></canvas>\n",
        "    <center>Data mining - Master on Computer Science</center>\n",
        "    <center><img src=\"https://github.com/deinok/EXPLOTACIO-DE-DADES/blob/main/ASSIGNAMENT_1/M-UdL2.png?raw=1\"  width=\"200\" alt=\"UdL Logo\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5QnAsWuxwMV"
      },
      "source": [
        "In this notebook, we study the PageRank algorithm used to rank (order) web pages by a ranking order based on the probability to reach a web page performing a \"random walk\" trough the web graph. The web graph we consider is the one where nodes represent web pages, and directed edges represent directed links (a link from page A to page B is represented as a directed edge from A to B in the web graph).\n",
        "\n",
        "We focus on a simple version of Page Rank, where the update formula for the pagerank of a webpage does not consider the \"dampling factor\" that is actually considered in implementations of PageRank that try to take into account the problem of \"dangling nodes\" and \"disconnected components\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI7sEwPwxwMW"
      },
      "source": [
        "Preliminary start-up code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3FjDVxcKxwMW"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pv-WdKUOxwMX",
        "outputId": "bd7222f0-7f4f-45b5-9a47-f883daec18b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://046b82acbfd7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pyspark\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import sys\n",
        "\n",
        "\n",
        "spark_home = os.environ.get('SPARK_HOME', None)\n",
        "print ( spark_home )\n",
        "sc = pyspark.SparkContext('local[*]')\n",
        "sc.setLogLevel('ERROR')\n",
        "sc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVaYNcCAxwMY"
      },
      "source": [
        "# Random Walk\n",
        "\n",
        "Consider a  **random walk** trough the following simple graph:\n",
        "\n",
        "\n",
        "<div>\n",
        "<img style=\"float: center;\" src=\"https://github.com/deinok/EXPLOTACIO-DE-DADES/blob/main/ASSIGNAMENT_1/graph1-s0.png?raw=1\" width =\"300px\"  />\n",
        "</div>\n",
        "\n",
        "Consider that at the beginning we start a random walk at any node with the same probability:\n",
        "\n",
        "$$ \\pi⁰ = [1/5,1/5,1/5,1/5,1/5] $$\n",
        "\n",
        "What will happen after many steps of the random walk ? It seems like we should end with high probability at the central node $n0$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "jZGgAjzVxwMZ"
      },
      "source": [
        "## Random Walk Example 1\n",
        "\n",
        "After one step, the probability to move to node $ni$ is updated as:\n",
        "\n",
        "$$ \\pi^1(i) = \\sum_{nodes \\ j \\ that \\ link \\ to \\ i} \\pi^0(j) \\frac{1}{odeg(j)}   $$\n",
        "\n",
        "where $odeg(j)$ is the number of **outgoing edges from node j**. Then:\n",
        "\n",
        "$$  \\pi^1 = [(1/5+1/5+1/5+1/5),0,0,0,0] $$\n",
        "\n",
        "Observe that we talk about the probability to move to a particular node, and because once we reach node $n0$ we will not move anymore, because this node has no \"outgoing\" edges, at this step the probability \"to move\" to node n0 is 4/5 (if we started at n0 at the beginning we did not move anymore at this step). This is the problem of what it is called \"dangling nodes\" (nodes that make the random walk to stop).\n",
        "\n",
        "But the relevant point here is that if we repeat these steps many times, the final probability values we get can be used as a measure of the \"relevance\" of that node, because that value indicates how likely is the event that we reach that node of the graph after many steps (assuming no dangling nodes are in the graph)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqHdmRkzxwMa"
      },
      "source": [
        "## Random Walk Example 2, no dangling nodes\n",
        "\n",
        "We can modify the example to make dissapear the problem of dangling nodes by make a self-loop in that node:\n",
        "\n",
        "<div>\n",
        "<img style=\"float: center;\" src=\"https://github.com/deinok/EXPLOTACIO-DE-DADES/blob/main/ASSIGNAMENT_1/graph2-s0.png?raw=1\" width =\"500px\"  />\n",
        "</div>\n",
        "\n",
        "\n",
        "Then, a random walk in this graph will never stop, and now the probability \"of being\" at the different nodes after 1 step is:\n",
        "\n",
        "$$  \\pi^1 = [1,0,0,0,0] $$\n",
        "\n",
        "Thanks to the fact that now node $n_0$ has a link to itself, so the formula for this node after one step is:\n",
        "\n",
        "\n",
        "$$  \\pi^1(0) = \\sum_{nodes \\ j \\ that \\ link \\ to \\ 0} \\pi^0(j) \\frac{1}{odeg(j)} = (1/5+1/5+1/5+1/5+1/5) = 1$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsqQgpMUxwMa"
      },
      "source": [
        "So, it is clear that from this time updating the formula will not modify the probabilities any more:\n",
        "\n",
        "$$  \\pi^2(0) = \\sum_{nodes \\ j \\ that \\ link \\ to \\ 0} \\pi^1(j) \\frac{1}{odeg(j)} = (1+0/5+0/5+0/5+0/5) = 1$$\n",
        "\n",
        "and for any other node ni different from $n_0$:\n",
        "\n",
        "$$ i \\neq 0 \\rightarrow \\pi^2(i) = \\sum_{nodes \\ j \\ that \\ link \\ to \\ i} \\pi^1(j) \\frac{1}{deg(j)} = 0$$\n",
        "\n",
        "as the other nodes do not have any incoming links\n",
        "\n",
        "So, we say that we have reached an stationary distribution. And using the distribution as a way to \"rank\" the nodes, we can conclude that the most relevant node is the node  $n_0$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgH-DRx1xwMa"
      },
      "source": [
        "### Random Walk Example 3, no dangling nodes\n",
        "\n",
        "Ok, but in general graphs will have more links, and we will need to simulate \"more steps\" to reach an stable distribution. Consider this modified example:\n",
        "\n",
        "<div>\n",
        "<img style=\"center;\" src=\"https://github.com/deinok/EXPLOTACIO-DE-DADES/blob/main/ASSIGNAMENT_1/graph3-s0.png?raw=1\" width =\"500px\"  />\n",
        "</div>\n",
        "\n",
        "Initial distribution:\n",
        "$$ \\pi^{0} = [1/5,1/5,1/5,1/5,1/5] $$\n",
        "\n",
        "After first step:\n",
        "\n",
        "$$ \\pi^1 = [1/5*(1/2)+(4/5),1/5*(1/2),0,0,0] = [0.9,0.1,0,0,0] $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9CgbOCMxwMa"
      },
      "source": [
        "After second step:\n",
        "\n",
        "$$ \\pi^2 = [0.9*(1/2)+0.1,0.9*(1/2),0,0,0] = [0.55,0.45,0,0,0] $$\n",
        "\n",
        "After third step:\n",
        "\n",
        "$$ \\pi^3 = [0.55*(1/2)+0.45,0.55*(1/2),0,0,0] = [0.725,0.275,0,0,0] $$\n",
        "\n",
        "After fourth step:\n",
        "\n",
        "$$ \\pi^4 = [0.725*(1/2)+0.275,0.725*(1/2),0,0,0] = [0.6375,0.3625,0,0,0] $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiSEclroxwMb"
      },
      "source": [
        "After fith step:\n",
        "\n",
        "$$ \\pi^5 = [0.6375*(1/2)+0.3625,0.6375*(1/2),0,0,0] = [0.6812,0.3187,0,0,0] $$\n",
        "\n",
        "After sixth step:\n",
        "\n",
        "$$ \\pi^6= [0.6812*(1/2)+0.3187,0.6812*(1/2),0,0,0] = [0.6593,0.3406,0,0,0] $$\n",
        "\n",
        "...\n",
        "\n",
        "After 20th step:\n",
        "\n",
        "$$ \\pi^{20} = [0.6666,0.3333,0,0,0] $$\n",
        "\n",
        "So, in this modified example the rank is distributed among the first two vertices (but still the most relevant is the first one). But observe that we need some more iterations to reach the stable distribution!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "BhkfGdpXxwMb"
      },
      "source": [
        "# The PageRank Algorithm\n",
        "\n",
        "So, the PageRank algorithm for a directed graph with no dangling nodes is simply the iterated update of the previous equation that computes the probability of being on the different nodes after a random walk of many steps:\n",
        "\n",
        "At iteration t+1, the rank vector $\\pi^{t+1}$ is updated as:\n",
        "            \n",
        "$$  \\pi^{t+1}(i) = \\sum_{nodes \\ j \\ that \\ link \\ to \\ i} \\pi^t(j) \\frac{1}{odeg(j)}  $$\n",
        "\n",
        "When do we stop iterating ?\n",
        "- The best option would be to stop when we reach a point where the solution is almost stable (no significant changes from $ \\pi^t$ to $ \\pi^{t+1}$).\n",
        "- We can also use some maximum number of iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "yv112EhpxwMb"
      },
      "source": [
        "## High-level pseudo-code of the PageRank algorithm\n",
        "\n",
        ">LinksRDD = { (j, $[i_1,i_2,...,i_k]$)  | there is a link from j to $i_{l}$ }  \n",
        ">$\\pi^0$ := [1/n,1/n,...,1/n]  \n",
        ">RankRDD = { $(j,\\pi^0[j])$  |  for  all  the  nodes  j }  \n",
        ">t=0  \n",
        ">While ( *rank vector $\\pi^t$ not stable* ) do:\n",
        ">>// Join linksRDD with RankRDD to get pairs of the kind:  \n",
        ">>// { ( j , ( [i1,i2,...,ik], $\\pi^t[j]$ )) | for any node j }  \n",
        ">>LinksRankInfoRDD = LinksRDD.join( RankRDD )  \n",
        ">>// compute all the contributions from  node j to target node i  \n",
        ">>flatContRDD = $\\{ (i, \\pi^t(j) \\frac{1}{odeg(j)}  ) \\ | \\ for \\ any \\ edge \\ j\\rightarrow i \\} $  \n",
        ">>// Reduce all the elements with the same key i  \n",
        ">>// to get $ \\pi^{t+1}[i] = \\sum_{j \\ edge \\ to \\ i}  \\pi^t(j) \\frac{1}{odeg(j)} $  \n",
        ">>RankRDD = flatContRDD.ReduceByKey( x,y : x+y )  \n",
        ">>t=t+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "4zgKvVI-xwMb"
      },
      "source": [
        "# PageRank Implementation in map-reduce\n",
        "\n",
        "To implement the algorithm with map-reduce, we need to mantain two main RDDs:\n",
        "1. The main one, **that will not change** (LinksRDD), represents the set of all the links $ j \\rightarrow i $ for any node j. That is, a suitable representation of the graph. We will using key,value records of this kind:\n",
        "    $$ (j, [i_1,i_2,...,i_k]) $$\n",
        "   that indicate that there is a link from node j to any node in the list\n",
        "2. The second one is the rank vector (RankRDD), that will be updated with a new one in each iteration (from the point of view of spark the RDD for $   \\pi^{t+1} $ will be created and the one for  $   \\pi^{t} $   will be eliminated)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [],
        "id": "sDlBeUyTxwMb"
      },
      "outputs": [],
      "source": [
        "# Example 1, with a dangling node\n",
        "LinksRDD = sc.parallelize([(0, []), (1, [0]), (2, [0]), (3, [0]), (4, [0])])\n",
        "RankRDD = sc.parallelize([(0, 1/5), (1, 1/5), (2, 1/5), (3, 1/5), (4, 1/5)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0ftx3V6HxwMc"
      },
      "outputs": [],
      "source": [
        "# Example 2\n",
        "LinksRDD = sc.parallelize([(0, [0]), (1, [0]), (2, [0]), (3, [0]), (4, [0])])\n",
        "RankRDD = sc.parallelize([(0, 1/5), (1, 1/5), (2, 1/5), (3, 1/5), (4, 1/5)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cavOPuOuxwMc"
      },
      "outputs": [],
      "source": [
        "# Example 3\n",
        "LinksRDD = sc.parallelize([(0, [0, 1]), (1, [0]), (2, [0]), (3, [0]), (4, [0])])\n",
        "RankRDD = sc.parallelize([(0, 1/5), (1, 1/5), (2, 1/5), (3, 1/5), (4, 1/5)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UGsHBt1DxwMc"
      },
      "outputs": [],
      "source": [
        "# Example 4, two disconnected subgraphs\n",
        "LinksRDD = sc.parallelize([(0, [1]), (1, [2]), (2, [0]), (3, [4]), (4, [5]), (5, [3])])\n",
        "RankRDD = sc.parallelize([(0, 1/6), (1, 1/6), (2, 1/6), (3, 1/6), (4, 1/6), (5, 1/6)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhlJJy_RxwMc"
      },
      "source": [
        "## Exercise, implement PageRank\n",
        "\n",
        "Implement PageRank using the next function to map a record of the type\n",
        "(j,  (list of nodes to which j points to, current rank of j))\n",
        "\n",
        "to a flat list of records of the type:\n",
        "\n",
        "( i, rank(j)/odeg(j) )\n",
        "\n",
        "where there is a node FROM j TO i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FHslNqR2xwMc"
      },
      "outputs": [],
      "source": [
        "def getContributions(linksAndRank):\n",
        "    j = linksAndRank[0]\n",
        "    targets = linksAndRank[1][0]\n",
        "    rankj = linksAndRank[1][1]\n",
        "    odegj = float(len(targets))\n",
        "    # Iterate over all pages i with a link from j (j -> i)\n",
        "    return [ (i, rankj / odegj) for i in targets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bEPFRqNjxwMd",
        "outputId": "d38edce4-0c5a-4515-a78c-ce0990ed4a77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time 0: [(0, 0.2), (1, 0.2), (2, 0.2), (3, 0.2), (4, 0.2)]\n",
            "time  1 : [(0, 0.8999999999999999), (1, 0.1)]\n",
            "time  2 : [(0, 0.5499999999999999), (1, 0.44999999999999996)]\n",
            "time  3 : [(0, 0.7249999999999999), (1, 0.27499999999999997)]\n",
            "time  4 : [(0, 0.6375), (1, 0.36249999999999993)]\n",
            "time  5 : [(0, 0.6812499999999999), (1, 0.31875)]\n",
            "time  6 : [(0, 0.6593749999999999), (1, 0.34062499999999996)]\n",
            "time  7 : [(0, 0.6703124999999999), (1, 0.32968749999999997)]\n",
            "time  8 : [(0, 0.66484375), (1, 0.33515624999999993)]\n",
            "time  9 : [(0, 0.6675781249999999), (1, 0.332421875)]\n",
            "time  10 : [(0, 0.6662109374999999), (1, 0.33378906249999996)]\n"
          ]
        }
      ],
      "source": [
        "print (\"time 0:\", RankRDD.collect())\n",
        "iter = 1\n",
        "while (iter <= 10):\n",
        "    LinksRankInfo = LinksRDD.join(RankRDD)\n",
        "    flatContributions = LinksRankInfo.flatMap(getContributions)\n",
        "    RankRDD = flatContributions.reduceByKey(lambda x, y : x + y)\n",
        "    print ( \"time \", iter, \":\", RankRDD.collect() )\n",
        "    iter = iter + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASSIGNAMENT 1"
      ],
      "metadata": {
        "id": "_R9v-c6tzQgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 1\n",
        "You must implement in the right way the PageRank algorithm, and include plenty of explanatory comments in each step of your functions. But you must implement the version actually introduced by google, that considers a \"damping\" factor. This time, at each step with probability d the random walk proceeds in the regular way, but with probability (1-d) you jump randomly to any node of the graph. In that case, the update equation at time t+1 is equal to:\n",
        "πt+1(i)=1−dN+d⋅(∑nodes j that link to iπt(j)1odeg(j))"
      ],
      "metadata": {
        "id": "knjNclOTztF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getContributionsWithDamping(linksAndRank):\n",
        "  j = linksAndRank[0]\n",
        "  targets = linksAndRank[1][0]\n",
        "  rankj = linksAndRank[1][1]\n",
        "  odegj = float(len(targets))\n",
        "  # Iterate over all pages i with a link from j (j -> i)\n",
        "  return [ (i, rankj / odegj) for i in targets]\n",
        "\n",
        "def compute_pagerank(LinksRDD: pyspark.rdd.RDD, d=0.85, max_iter=10, verbose=False):\n",
        "  print(\"LinksRDD:\", LinksRDD.collect())\n",
        "\n",
        "  # Set of all nodes (ensures nodes with no in-links still get a rank)\n",
        "  NodesRDD = LinksRDD.keys() \\\n",
        "    .distinct()\n",
        "\n",
        "  # N = number of nodes\n",
        "  N = NodesRDD.count()\n",
        "\n",
        "  # If no numbers exist, early return\n",
        "  if N == 0:\n",
        "      return LinksRDD.context.parallelize([])\n",
        "\n",
        "  # Uniform initialization: sum(ranks) = 1\n",
        "  RankRDD = NodesRDD \\\n",
        "    .map(lambda i: (i, 1.0 / N))\n",
        "\n",
        "  # Teleportation term: with prob (1-d) jump uniformly to any node\n",
        "  teleport = (1.0 - d) / N\n",
        "\n",
        "  print(\"time 0:\", RankRDD.collect())\n",
        "  iter = 1\n",
        "  while (iter <= max_iter):\n",
        "      LinksRankInfo = LinksRDD.join(RankRDD)\n",
        "      flatContributions = LinksRankInfo.flatMap(getContributionsWithDamping)\n",
        "      RankRDD = flatContributions.reduceByKey(lambda x, y : x + y)\n",
        "      print(\"time \", iter, \":\", RankRDD.collect())\n",
        "      iter = iter + 1\n",
        "  return RankRDD"
      ],
      "metadata": {
        "id": "PN8fiTqBzU-u"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RankRDD = compute_pagerank(LinksRDD, d=0.85, max_iter=100, tol=1e-10, verbose=True)\n"
      ],
      "metadata": {
        "id": "jIqu_XPDzcOF",
        "outputId": "5171a87c-f7f8-48b9-8e8d-75d41abf1238",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinksRDD: [(0, [0, 1]), (1, [0]), (2, [0]), (3, [0]), (4, [0])]\n",
            "time 0: [(0, 0.2), (2, 0.2), (4, 0.2), (1, 0.2), (3, 0.2)]\n",
            "time  1 : [(0, 0.8999999999999999), (1, 0.1)]\n",
            "time  2 : [(0, 0.5499999999999999), (1, 0.44999999999999996)]\n",
            "time  3 : [(0, 0.7249999999999999), (1, 0.27499999999999997)]\n",
            "time  4 : [(0, 0.6375), (1, 0.36249999999999993)]\n",
            "time  5 : [(0, 0.6812499999999999), (1, 0.31875)]\n",
            "time  6 : [(0, 0.6593749999999999), (1, 0.34062499999999996)]\n",
            "time  7 : [(0, 0.6703124999999999), (1, 0.32968749999999997)]\n",
            "time  8 : [(0, 0.66484375), (1, 0.33515624999999993)]\n",
            "time  9 : [(0, 0.6675781249999999), (1, 0.332421875)]\n",
            "time  10 : [(0, 0.6662109374999999), (1, 0.33378906249999996)]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}