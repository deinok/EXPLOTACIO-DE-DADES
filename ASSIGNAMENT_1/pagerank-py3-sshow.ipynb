{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUYNznMdxwMU"
      },
      "source": [
        "<center><span style=\"color:blue; font-family:Georgia;  font-size:2em;\">\n",
        "    <h1>PageRank</h1></span></center>\n",
        "    <p> </p>\n",
        "    <p> </p>\n",
        "    <center><span style=\"color:blue; font-family:Georgia;  font-size:1em;\">\n",
        "    Ramon Béjar</span></center>\n",
        "    <canvas id=\"myCanvas\" width=\"200\" height=\"100\" style=\"border:0px solid\"></canvas>\n",
        "    <center>Data mining - Master on Computer Science</center>\n",
        "    <center><img src=\"https://github.com/deinok/EXPLOTACIO-DE-DADES/blob/main/ASSIGNAMENT_1/M-UdL2.png?raw=1\"  width=\"200\" alt=\"UdL Logo\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5QnAsWuxwMV"
      },
      "source": [
        "In this notebook, we study the PageRank algorithm used to rank (order) web pages by a ranking order based on the probability to reach a web page performing a \"random walk\" trough the web graph. The web graph we consider is the one where nodes represent web pages, and directed edges represent directed links (a link from page A to page B is represented as a directed edge from A to B in the web graph).\n",
        "\n",
        "We focus on a simple version of Page Rank, where the update formula for the pagerank of a webpage does not consider the \"dampling factor\" that is actually considered in implementations of PageRank that try to take into account the problem of \"dangling nodes\" and \"disconnected components\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI7sEwPwxwMW"
      },
      "source": [
        "Preliminary start-up code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FjDVxcKxwMW"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv-WdKUOxwMX",
        "outputId": "c36661a9-8fdb-4d20-ecd9-b1365e6550bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://36e4d39db512:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pyspark\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import sys\n",
        "\n",
        "\n",
        "spark_home = os.environ.get('SPARK_HOME', None)\n",
        "print ( spark_home )\n",
        "sc = pyspark.SparkContext('local[*]')\n",
        "sc.setLogLevel('ERROR')\n",
        "sc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVaYNcCAxwMY"
      },
      "source": [
        "# Random Walk\n",
        "\n",
        "Consider a  **random walk** trough the following simple graph:\n",
        "\n",
        "\n",
        "<div>\n",
        "<img style=\"float: center;\" src=\"https://github.com/deinok/EXPLOTACIO-DE-DADES/blob/main/ASSIGNAMENT_1/graph1-s0.png?raw=1\" width =\"300px\"  />\n",
        "</div>\n",
        "\n",
        "Consider that at the beginning we start a random walk at any node with the same probability:\n",
        "\n",
        "$$ \\pi⁰ = [1/5,1/5,1/5,1/5,1/5] $$\n",
        "\n",
        "What will happen after many steps of the random walk ? It seems like we should end with high probability at the central node $n0$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "jZGgAjzVxwMZ"
      },
      "source": [
        "## Random Walk Example 1\n",
        "\n",
        "After one step, the probability to move to node $ni$ is updated as:\n",
        "\n",
        "$$ \\pi^1(i) = \\sum_{nodes \\ j \\ that \\ link \\ to \\ i} \\pi^0(j) \\frac{1}{odeg(j)}   $$\n",
        "\n",
        "where $odeg(j)$ is the number of **outgoing edges from node j**. Then:\n",
        "\n",
        "$$  \\pi^1 = [(1/5+1/5+1/5+1/5),0,0,0,0] $$\n",
        "\n",
        "Observe that we talk about the probability to move to a particular node, and because once we reach node $n0$ we will not move anymore, because this node has no \"outgoing\" edges, at this step the probability \"to move\" to node n0 is 4/5 (if we started at n0 at the beginning we did not move anymore at this step). This is the problem of what it is called \"dangling nodes\" (nodes that make the random walk to stop).\n",
        "\n",
        "But the relevant point here is that if we repeat these steps many times, the final probability values we get can be used as a measure of the \"relevance\" of that node, because that value indicates how likely is the event that we reach that node of the graph after many steps (assuming no dangling nodes are in the graph)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqHdmRkzxwMa"
      },
      "source": [
        "## Random Walk Example 2, no dangling nodes\n",
        "\n",
        "We can modify the example to make dissapear the problem of dangling nodes by make a self-loop in that node:\n",
        "\n",
        "<div>\n",
        "<img style=\"float: center;\" src=\"https://github.com/deinok/EXPLOTACIO-DE-DADES/blob/main/ASSIGNAMENT_1/graph2-s0.png?raw=1\" width =\"500px\"  />\n",
        "</div>\n",
        "\n",
        "\n",
        "Then, a random walk in this graph will never stop, and now the probability \"of being\" at the different nodes after 1 step is:\n",
        "\n",
        "$$  \\pi^1 = [1,0,0,0,0] $$\n",
        "\n",
        "Thanks to the fact that now node $n_0$ has a link to itself, so the formula for this node after one step is:\n",
        "\n",
        "\n",
        "$$  \\pi^1(0) = \\sum_{nodes \\ j \\ that \\ link \\ to \\ 0} \\pi^0(j) \\frac{1}{odeg(j)} = (1/5+1/5+1/5+1/5+1/5) = 1$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsqQgpMUxwMa"
      },
      "source": [
        "So, it is clear that from this time updating the formula will not modify the probabilities any more:\n",
        "\n",
        "$$  \\pi^2(0) = \\sum_{nodes \\ j \\ that \\ link \\ to \\ 0} \\pi^1(j) \\frac{1}{odeg(j)} = (1+0/5+0/5+0/5+0/5) = 1$$\n",
        "\n",
        "and for any other node ni different from $n_0$:\n",
        "\n",
        "$$ i \\neq 0 \\rightarrow \\pi^2(i) = \\sum_{nodes \\ j \\ that \\ link \\ to \\ i} \\pi^1(j) \\frac{1}{deg(j)} = 0$$\n",
        "\n",
        "as the other nodes do not have any incoming links\n",
        "\n",
        "So, we say that we have reached an stationary distribution. And using the distribution as a way to \"rank\" the nodes, we can conclude that the most relevant node is the node  $n_0$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgH-DRx1xwMa"
      },
      "source": [
        "### Random Walk Example 3, no dangling nodes\n",
        "\n",
        "Ok, but in general graphs will have more links, and we will need to simulate \"more steps\" to reach an stable distribution. Consider this modified example:\n",
        "\n",
        "<div>\n",
        "<img style=\"center;\" src=\"https://github.com/deinok/EXPLOTACIO-DE-DADES/blob/main/ASSIGNAMENT_1/graph3-s0.png?raw=1\" width =\"500px\"  />\n",
        "</div>\n",
        "\n",
        "Initial distribution:\n",
        "$$ \\pi^{0} = [1/5,1/5,1/5,1/5,1/5] $$\n",
        "\n",
        "After first step:\n",
        "\n",
        "$$ \\pi^1 = [1/5*(1/2)+(4/5),1/5*(1/2),0,0,0] = [0.9,0.1,0,0,0] $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9CgbOCMxwMa"
      },
      "source": [
        "After second step:\n",
        "\n",
        "$$ \\pi^2 = [0.9*(1/2)+0.1,0.9*(1/2),0,0,0] = [0.55,0.45,0,0,0] $$\n",
        "\n",
        "After third step:\n",
        "\n",
        "$$ \\pi^3 = [0.55*(1/2)+0.45,0.55*(1/2),0,0,0] = [0.725,0.275,0,0,0] $$\n",
        "\n",
        "After fourth step:\n",
        "\n",
        "$$ \\pi^4 = [0.725*(1/2)+0.275,0.725*(1/2),0,0,0] = [0.6375,0.3625,0,0,0] $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiSEclroxwMb"
      },
      "source": [
        "After fith step:\n",
        "\n",
        "$$ \\pi^5 = [0.6375*(1/2)+0.3625,0.6375*(1/2),0,0,0] = [0.6812,0.3187,0,0,0] $$\n",
        "\n",
        "After sixth step:\n",
        "\n",
        "$$ \\pi^6= [0.6812*(1/2)+0.3187,0.6812*(1/2),0,0,0] = [0.6593,0.3406,0,0,0] $$\n",
        "\n",
        "...\n",
        "\n",
        "After 20th step:\n",
        "\n",
        "$$ \\pi^{20} = [0.6666,0.3333,0,0,0] $$\n",
        "\n",
        "So, in this modified example the rank is distributed among the first two vertices (but still the most relevant is the first one). But observe that we need some more iterations to reach the stable distribution!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "BhkfGdpXxwMb"
      },
      "source": [
        "# The PageRank Algorithm\n",
        "\n",
        "So, the PageRank algorithm for a directed graph with no dangling nodes is simply the iterated update of the previous equation that computes the probability of being on the different nodes after a random walk of many steps:\n",
        "\n",
        "At iteration t+1, the rank vector $\\pi^{t+1}$ is updated as:\n",
        "            \n",
        "$$  \\pi^{t+1}(i) = \\sum_{nodes \\ j \\ that \\ link \\ to \\ i} \\pi^t(j) \\frac{1}{odeg(j)}  $$\n",
        "\n",
        "When do we stop iterating ?\n",
        "- The best option would be to stop when we reach a point where the solution is almost stable (no significant changes from $ \\pi^t$ to $ \\pi^{t+1}$).\n",
        "- We can also use some maximum number of iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "yv112EhpxwMb"
      },
      "source": [
        "## High-level pseudo-code of the PageRank algorithm\n",
        "\n",
        ">LinksRDD = { (j, $[i_1,i_2,...,i_k]$)  | there is a link from j to $i_{l}$ }  \n",
        ">$\\pi^0$ := [1/n,1/n,...,1/n]  \n",
        ">RankRDD = { $(j,\\pi^0[j])$  |  for  all  the  nodes  j }  \n",
        ">t=0  \n",
        ">While ( *rank vector $\\pi^t$ not stable* ) do:\n",
        ">>// Join linksRDD with RankRDD to get pairs of the kind:  \n",
        ">>// { ( j , ( [i1,i2,...,ik], $\\pi^t[j]$ )) | for any node j }  \n",
        ">>LinksRankInfoRDD = LinksRDD.join( RankRDD )  \n",
        ">>// compute all the contributions from  node j to target node i  \n",
        ">>flatContRDD = $\\{ (i, \\pi^t(j) \\frac{1}{odeg(j)}  ) \\ | \\ for \\ any \\ edge \\ j\\rightarrow i \\} $  \n",
        ">>// Reduce all the elements with the same key i  \n",
        ">>// to get $ \\pi^{t+1}[i] = \\sum_{j \\ edge \\ to \\ i}  \\pi^t(j) \\frac{1}{odeg(j)} $  \n",
        ">>RankRDD = flatContRDD.ReduceByKey( x,y : x+y )  \n",
        ">>t=t+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "4zgKvVI-xwMb"
      },
      "source": [
        "# PageRank Implementation in map-reduce\n",
        "\n",
        "To implement the algorithm with map-reduce, we need to mantain two main RDDs:\n",
        "1. The main one, **that will not change** (LinksRDD), represents the set of all the links $ j \\rightarrow i $ for any node j. That is, a suitable representation of the graph. We will using key,value records of this kind:\n",
        "    $$ (j, [i_1,i_2,...,i_k]) $$\n",
        "   that indicate that there is a link from node j to any node in the list\n",
        "2. The second one is the rank vector (RankRDD), that will be updated with a new one in each iteration (from the point of view of spark the RDD for $   \\pi^{t+1} $ will be created and the one for  $   \\pi^{t} $   will be eliminated)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "sDlBeUyTxwMb"
      },
      "outputs": [],
      "source": [
        "# Example 1, with a dangling node\n",
        "LinksRDD = sc.parallelize( [(0,[]),(1,[0]),(2,[0]),(3,[0]),(4,[0])] )\n",
        "RankRDD = sc.parallelize( [(0,1/5),(1,1/5),(2,1/5),(3,1/5),(4,1/5)] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ftx3V6HxwMc"
      },
      "outputs": [],
      "source": [
        "# Example 2\n",
        "LinksRDD = sc.parallelize( [(0,[0]),(1,[0]),(2,[0]),(3,[0]),(4,[0])] )\n",
        "RankRDD = sc.parallelize( [(0,1/5),(1,1/5),(2,1/5),(3,1/5),(4,1/5)] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cavOPuOuxwMc"
      },
      "outputs": [],
      "source": [
        "# Example 3\n",
        "LinksRDD = sc.parallelize( [(0,[0,1]),(1,[0]),(2,[0]),(3,[0]),(4,[0])] )\n",
        "RankRDD = sc.parallelize( [(0,1/5),(1,1/5),(2,1/5),(3,1/5),(4,1/5)] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGsHBt1DxwMc"
      },
      "outputs": [],
      "source": [
        "# Example 4, two disconnected subgraphs\n",
        "LinksRDD = sc.parallelize( [(0,[1]),(1,[2]),(2,[0]), (3,[4]),(4,[5]),(5,[3])] )\n",
        "RankRDD = sc.parallelize( [(0,1/6),(1,1/6),(2,1/6),(3,1/6),(4,1/6), (5,1/6) ] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhlJJy_RxwMc"
      },
      "source": [
        "## Exercise, implement PageRank\n",
        "\n",
        "Implement PageRank using the next function to map a record of the type\n",
        "(j,  (list of nodes to which j points to, current rank of j))\n",
        "\n",
        "to a flat list of records of the type:\n",
        "\n",
        "( i, rank(j)/odeg(j) )\n",
        "\n",
        "where there is a node FROM j TO i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHslNqR2xwMc"
      },
      "outputs": [],
      "source": [
        "def getContributions( linksAndRank ):\n",
        "    j = linksAndRank[0]\n",
        "    targets = linksAndRank[1][0]\n",
        "    rankj = linksAndRank[1][1]\n",
        "    odegj = float(len(targets))\n",
        "    # Iterate over all pages i with a link from j (j -> i)\n",
        "    return [ (i,rankj/odegj) for i in targets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEPFRqNjxwMd",
        "outputId": "f94c915b-528d-49f1-80f2-f8864ebcadde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-3122899865.py, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3122899865.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    LinksRankInfo =\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "print ( \"time 0:\", RankRDD.collect() )\n",
        "iter = 1\n",
        "while (iter <= 10):\n",
        "    LinksRankInfo =\n",
        "    flatContributions =\n",
        "    RankRDD = flatContributions.reduceByKey( lambda x,y : x+y )\n",
        "    print ( \"time \",iter,\":\", RankRDD.collect() )\n",
        "    iter = iter +1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASSIGNAMENT 1"
      ],
      "metadata": {
        "id": "_R9v-c6tzQgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 1\n",
        "You must implement in the right way the PageRank algorithm, and include plenty of explanatory comments in each step of your functions. But you must implement the version actually introduced by google, that considers a \"damping\" factor. This time, at each step with probability d the random walk proceeds in the regular way, but with probability (1-d) you jump randomly to any node of the graph. In that case, the update equation at time t+1 is equal to:\n",
        "πt+1(i)=1−dN+d⋅(∑nodes j that link to iπt(j)1odeg(j))"
      ],
      "metadata": {
        "id": "knjNclOTztF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PageRank with damping and proper dangling-mass redistribution (original Google formulation)\n",
        "# Inputs:\n",
        "#   LinksRDD: RDD[(node, [out_neighbors...])]   -- every node appears exactly once as a key\n",
        "# Params:\n",
        "#   d: damping factor in (0,1)\n",
        "#   max_iter: hard cap on iterations\n",
        "#   tol: L1 convergence tolerance\n",
        "#\n",
        "# Output:\n",
        "#   RankRDD: RDD[(node, rank)] where ranks sum to 1\n",
        "\n",
        "from operator import add\n",
        "\n",
        "def compute_pagerank(LinksRDD, d=0.85, max_iter=100, tol=1e-12, verbose=False):\n",
        "    # ----- Precompute constants and helper RDDs -----\n",
        "    # Set of all nodes (ensures nodes with no in-links still get a rank)\n",
        "    NodesRDD = LinksRDD.keys().distinct().cache()\n",
        "\n",
        "    # N = number of nodes\n",
        "    N = NodesRDD.count()\n",
        "    if N == 0:\n",
        "        return LinksRDD.context.parallelize([])\n",
        "\n",
        "    # Uniform initialization: sum(ranks) = 1\n",
        "    RankRDD = NodesRDD.map(lambda i: (i, 1.0 / N)).cache()\n",
        "\n",
        "    # Teleportation term: with prob (1-d) jump uniformly to any node\n",
        "    teleport = (1.0 - d) / N\n",
        "\n",
        "    # Convenience: small function that yields contributions from a single source node\n",
        "    def contributions_from_source(j_links_rank):\n",
        "        \"\"\"\n",
        "        Input record: (j, ([i1, i2, ...], r_j))\n",
        "        Output iterator: (i, r_j / outdeg(j)) for each i in out-neighbors(j)\n",
        "        If outdeg(j) == 0, emit nothing here; its mass is handled as 'dangling' separately.\n",
        "        \"\"\"\n",
        "        j, (targets, rj) = j_links_rank\n",
        "        odeg = len(targets)\n",
        "        if odeg == 0:\n",
        "            return []  # dangling node; handled via dangling_mass\n",
        "        share = rj / odeg\n",
        "        return [(i, share) for i in targets]\n",
        "\n",
        "    # Iterative refinement\n",
        "    it = 0\n",
        "    while it < max_iter:\n",
        "        it += 1\n",
        "\n",
        "        # Join links with current ranks: (j, ([i...], r_j))\n",
        "        LinksRank = LinksRDD.join(RankRDD)  # shuffle once\n",
        "        LinksRank.persist()\n",
        "\n",
        "        # 1) Compute total dangling mass = sum of ranks of nodes with zero out-degree\n",
        "        dangling_mass = (\n",
        "            LinksRank\n",
        "            .filter(lambda jr: len(jr[1][0]) == 0)\n",
        "            .map(lambda jr: jr[1][1])  # r_j\n",
        "            .sum()\n",
        "        )\n",
        "\n",
        "        # 2) Push non-dangling contributions along outgoing edges\n",
        "        #    Raw contributions S_i = sum_{j->i} r_j / outdeg(j)\n",
        "        contribs = LinksRank.flatMap(contributions_from_source)\n",
        "\n",
        "        # Sum inbound contributions per target node\n",
        "        summed = contribs.reduceByKey(add)\n",
        "\n",
        "        # Ensure every node appears even if it got no inbound contribs this round\n",
        "        # Start with zeros for all nodes, then overlay summed contributions\n",
        "        inbound = (\n",
        "            NodesRDD.map(lambda i: (i, 0.0))\n",
        "            .leftOuterJoin(summed)  # (i, (0.0, maybe_sum))\n",
        "            .mapValues(lambda pair: pair[1] if pair[1] is not None else 0.0)\n",
        "        )\n",
        "\n",
        "        # 3) Apply damping and add teleportation and dangling redistribution\n",
        "        #    π_{t+1}(i) = (1-d)/N + d * [ S_i + dangling_mass / N ]\n",
        "        #    where S_i = sum_{j->i} r_j / outdeg(j)\n",
        "        newRank = inbound.mapValues(lambda Si: teleport + d * (Si + dangling_mass / N))\n",
        "\n",
        "        # 4) Convergence check on L1 difference: sum_i |π_{t+1}(i) - π_t(i)|\n",
        "        if tol is not None and tol > 0:\n",
        "            # Join old and new to compute L1 change\n",
        "            diff = (\n",
        "                RankRDD.join(newRank)\n",
        "                .map(lambda kv: abs(kv[1][0] - kv[1][1]))\n",
        "                .sum()\n",
        "            )\n",
        "            if verbose:\n",
        "                print(f\"iter {it:3d}  L1 diff = {diff:.3e}  dangling = {dangling_mass:.3e}\")\n",
        "            if diff < tol:\n",
        "                RankRDD.unpersist(blocking=False)\n",
        "                LinksRank.unpersist(blocking=False)\n",
        "                RankRDD = newRank.cache()\n",
        "                break\n",
        "\n",
        "        # 5) Prepare for next round\n",
        "        RankRDD.unpersist(blocking=False)\n",
        "        LinksRank.unpersist(blocking=False)\n",
        "        RankRDD = newRank.cache()\n",
        "\n",
        "    # Optional: normalize for numerical drift so sum ranks = 1 exactly\n",
        "    total = RankRDD.values().sum()\n",
        "    if total != 0:\n",
        "        RankRDD = RankRDD.mapValues(lambda r: r / total).cache()\n",
        "\n",
        "    return RankRDD\n",
        "\n",
        "# Example usage in your notebook:\n",
        "# print(\"time 0:\", RankRDD.collect())\n",
        "# RankRDD = compute_pagerank(LinksRDD, d=0.85, max_iter=100, tol=1e-10, verbose=True)\n",
        "# print(\"final:\", sorted(RankRDD.collect()))\n"
      ],
      "metadata": {
        "id": "PN8fiTqBzU-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage in your notebook:\n",
        "print(\"time 0:\", RankRDD.collect())\n",
        "RankRDD = compute_pagerank(LinksRDD, d=0.85, max_iter=100, tol=1e-10, verbose=True)\n",
        "print(\"final:\", sorted(RankRDD.collect()))"
      ],
      "metadata": {
        "id": "jIqu_XPDzcOF",
        "outputId": "943d1600-2b15-4e40-8a01-d2e795c76eb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time 0: [(0, 0.16666666666666666), (1, 0.16666666666666666), (2, 0.16666666666666666), (3, 0.16666666666666666), (4, 0.16666666666666666), (5, 0.16666666666666666)]\n",
            "iter   1  L1 diff = 0.000e+00  dangling = 0.000e+00\n",
            "final: [(0, 0.16666666666666669), (1, 0.16666666666666669), (2, 0.16666666666666669), (3, 0.16666666666666669), (4, 0.16666666666666669), (5, 0.16666666666666669)]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}